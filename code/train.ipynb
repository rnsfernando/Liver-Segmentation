{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df031cf-3ce9-410d-abd8-3a3e9e78450f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e143fbfd-330f-4d96-a0bb-be8504711da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.utils import first\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from monai.losses import DiceLoss\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, data_in, loss, optim, max_epochs, model_dir, test_interval=1 , device=torch.device(\"cuda:0\")):\n",
    "    best_metric = -1\n",
    "    best_metric_epoch = -1\n",
    "    save_loss_train = []\n",
    "    save_loss_test = []\n",
    "    save_metric_train = []\n",
    "    save_metric_test = []\n",
    "    train_loader, test_loader = data_in\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        print(\"-\" * 10)\n",
    "        print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "        model.train()\n",
    "        train_epoch_loss = 0\n",
    "        train_step = 0\n",
    "        epoch_metric_train = 0\n",
    "        for batch_data in train_loader:\n",
    "            \n",
    "            train_step += 1\n",
    "\n",
    "            volume = batch_data[\"vol\"]\n",
    "            label = batch_data[\"seg\"]\n",
    "            label = label != 0\n",
    "            volume, label = (volume.to(device), label.to(device))\n",
    "\n",
    "            optim.zero_grad()\n",
    "            outputs = model(volume)\n",
    "            \n",
    "            train_loss = loss(outputs, label)\n",
    "            \n",
    "            train_loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            train_epoch_loss += train_loss.item()\n",
    "            print(\n",
    "                f\"{train_step}/{len(train_loader) // train_loader.batch_size}, \"\n",
    "                f\"Train_loss: {train_loss.item():.4f}\")\n",
    "\n",
    "            train_metric = dice_metric(outputs, label)\n",
    "            epoch_metric_train += train_metric\n",
    "            print(f'Train_dice: {train_metric:.4f}')\n",
    "\n",
    "        print('-'*20)\n",
    "        \n",
    "        train_epoch_loss /= train_step\n",
    "        print(f'Epoch_loss: {train_epoch_loss:.4f}')\n",
    "        save_loss_train.append(train_epoch_loss)\n",
    "        np.save(os.path.join(model_dir, 'loss_train.npy'), save_loss_train)\n",
    "        \n",
    "        epoch_metric_train /= train_step\n",
    "        print(f'Epoch_metric: {epoch_metric_train:.4f}')\n",
    "\n",
    "        save_metric_train.append(epoch_metric_train)\n",
    "        np.save(os.path.join(model_dir, 'metric_train.npy'), save_metric_train)\n",
    "\n",
    "        if (epoch + 1) % test_interval == 0:\n",
    "\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                test_epoch_loss = 0\n",
    "                test_metric = 0\n",
    "                epoch_metric_test = 0\n",
    "                test_step = 0\n",
    "\n",
    "                for test_data in test_loader:\n",
    "\n",
    "                    test_step += 1\n",
    "\n",
    "                    test_volume = test_data[\"vol\"]\n",
    "                    test_label = test_data[\"seg\"]\n",
    "                    test_label = test_label != 0\n",
    "                    test_volume, test_label = (test_volume.to(device), test_label.to(device),)\n",
    "                    \n",
    "                    test_outputs = model(test_volume)\n",
    "                    \n",
    "                    test_loss = loss(test_outputs, test_label)\n",
    "                    test_epoch_loss += test_loss.item()\n",
    "                    test_metric = dice_metric(test_outputs, test_label)\n",
    "                    epoch_metric_test += test_metric\n",
    "                    \n",
    "                \n",
    "                test_epoch_loss /= test_step\n",
    "                print(f'test_loss_epoch: {test_epoch_loss:.4f}')\n",
    "                save_loss_test.append(test_epoch_loss)\n",
    "                np.save(os.path.join(model_dir, 'loss_test.npy'), save_loss_test)\n",
    "\n",
    "                epoch_metric_test /= test_step\n",
    "                print(f'test_dice_epoch: {epoch_metric_test:.4f}')\n",
    "                save_metric_test.append(epoch_metric_test)\n",
    "                np.save(os.path.join(model_dir, 'metric_test.npy'), save_metric_test)\n",
    "\n",
    "                if epoch_metric_test > best_metric:\n",
    "                    best_metric = epoch_metric_test\n",
    "                    best_metric_epoch = epoch + 1\n",
    "                    torch.save(model.state_dict(), os.path.join(\n",
    "                        model_dir, \"best_metric_model.pth\"))\n",
    "                \n",
    "                print(\n",
    "                    f\"current epoch: {epoch + 1} current mean dice: {test_metric:.4f}\"\n",
    "                    f\"\\nbest mean dice: {best_metric:.4f} \"\n",
    "                    f\"at epoch: {best_metric_epoch}\"\n",
    "                )\n",
    "\n",
    "\n",
    "    print(\n",
    "        f\"train completed, best_metric: {best_metric:.4f} \"\n",
    "        f\"at epoch: {best_metric_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7276a39-69c8-46fb-a3fb-f0dfd0de696b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import dicom2nifti\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    EnsureChannelFirstD,\n",
    "    LoadImaged,\n",
    "    Resized,\n",
    "    ToTensord,\n",
    "    Spacingd,\n",
    "    Orientationd,\n",
    "    ScaleIntensityRanged,\n",
    "    CropForegroundd,\n",
    "\n",
    ")\n",
    "from monai.data import DataLoader, Dataset, CacheDataset\n",
    "from monai.utils import set_determinism\n",
    "\n",
    "\n",
    "def prepare(in_dir, pixdim=(1.5, 1.5, 1.0), a_min=-200, a_max=200, spatial_size=[128, 128, 86], cache=True):\n",
    "    \"\"\"\n",
    "    This function is for preprocessing, it contains only the basic transforms, but you can add more operations that you\n",
    "    find in the Monai documentation.\n",
    "    https://monai.io/docs.html\n",
    "    \"\"\"\n",
    "\n",
    "    set_determinism(seed=0)\n",
    "\n",
    "    path_train_volumes = sorted(glob(os.path.join(in_dir, \"TrainVolumes\", \"*.nii.gz\")))\n",
    "    path_train_segmentation = sorted(glob(os.path.join(in_dir, \"TrainSegmentation\", \"*.nii.gz\")))\n",
    "\n",
    "    path_test_volumes = sorted(glob(os.path.join(in_dir, \"TestVolumes\", \"*.nii.gz\")))\n",
    "    path_test_segmentation = sorted(glob(os.path.join(in_dir, \"TestSegmentation\", \"*.nii.gz\")))\n",
    "\n",
    "    train_files = [{\"vol\": image_name, \"seg\": label_name} for image_name, label_name in\n",
    "                   zip(path_train_volumes, path_train_segmentation)]\n",
    "    test_files = [{\"vol\": image_name, \"seg\": label_name} for image_name, label_name in\n",
    "                  zip(path_test_volumes, path_test_segmentation)]\n",
    "\n",
    "    train_transforms = Compose(#allow to apply multiple transforms same time\n",
    "        [\n",
    "            LoadImaged(keys=[\"vol\", \"seg\"]),\n",
    "            EnsureChannelFirstD(keys=[\"vol\", \"seg\"]),\n",
    "            Spacingd(keys=[\"vol\", \"seg\"], pixdim=pixdim, mode=(\"bilinear\", \"nearest\")),\n",
    "            Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n",
    "            ScaleIntensityRanged(keys=[\"vol\"], a_min=a_min, a_max=a_max, b_min=0.0, b_max=1.0, clip=True),\n",
    "            CropForegroundd(keys=[\"vol\", \"seg\"], source_key=\"vol\"),\n",
    "            Resized(keys=[\"vol\", \"seg\"], spatial_size=spatial_size),\n",
    "            ToTensord(keys=[\"vol\", \"seg\"]),\n",
    "\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    test_transforms = Compose(\n",
    "        [#functions from monai(not all. only few)\n",
    "            LoadImaged(keys=[\"vol\", \"seg\"]),\n",
    "            EnsureChannelFirstD(keys=[\"vol\", \"seg\"]),\n",
    "            Spacingd(keys=[\"vol\", \"seg\"], pixdim=pixdim, mode=(\"bilinear\", \"nearest\")),\n",
    "            Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n",
    "            ScaleIntensityRanged(keys=[\"vol\"], a_min=a_min, a_max=a_max, b_min=0.0, b_max=1.0, clip=True),\n",
    "            CropForegroundd(keys=['vol', 'seg'], source_key='vol'),\n",
    "            Resized(keys=[\"vol\", \"seg\"], spatial_size=spatial_size),\n",
    "            ToTensord(keys=[\"vol\", \"seg\"]),\n",
    "\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if cache:\n",
    "        train_ds = CacheDataset(data=train_files, transform=train_transforms, cache_rate=1.0)\n",
    "        train_loader = DataLoader(train_ds, batch_size=1)\n",
    "\n",
    "        test_ds = CacheDataset(data=test_files, transform=test_transforms, cache_rate=1.0)\n",
    "        test_loader = DataLoader(test_ds, batch_size=1)\n",
    "\n",
    "        return train_loader, test_loader\n",
    "\n",
    "    else:\n",
    "        train_ds = Dataset(data=train_files, transform=train_transforms)\n",
    "        train_loader = DataLoader(train_ds, batch_size=1)\n",
    "\n",
    "        test_ds = Dataset(data=test_files, transform=test_transforms)\n",
    "        test_loader = DataLoader(test_ds, batch_size=1)\n",
    "\n",
    "        return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3270c96c-8966-4e1f-ba7c-8ec96ccce680",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\anaconda3\\envs\\Liver_Segmentation\\lib\\site-packages\\monai\\utils\\deprecate_utils.py:321: FutureWarning: monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "  warn_deprecated(argname, msg, warning_category)\n",
      "Loading dataset: 100%|██████████| 187/187 [22:16<00:00,  7.15s/it]\n",
      "Loading dataset: 100%|██████████| 48/48 [07:26<00:00,  9.30s/it]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'dimensions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m data_in \u001b[38;5;241m=\u001b[39m prepare(data_dir, cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     11\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mUNet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdimensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;66;43;03m#3-is 3D since we do volume segmentation\u001b[39;49;00m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;66;43;03m#because we masked with only one channel(that means each slice has only one channel )\u001b[39;49;00m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;66;43;03m#this value should be equal to the number of classes outputs (channel1- pixel prob. for background, channel2- pixel prob. for foreground)\u001b[39;49;00m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchannels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_res_units\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNorm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBATCH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m#loss_function = DiceCELoss(to_onehot_y=True, sigmoid=True, squared_pred=True, ce_weight=calculate_weights(1792651250,2510860).to(device))\u001b[39;00m\n\u001b[0;32m     24\u001b[0m loss_function \u001b[38;5;241m=\u001b[39m DiceLoss(to_onehot_y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, sigmoid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, squared_pred\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'dimensions'"
     ]
    }
   ],
   "source": [
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.losses import DiceLoss, DiceCELoss\n",
    "\n",
    "import torch\n",
    "\n",
    "data_dir = r'E:\\Medical imaging\\Liver segmentation\\final data set'\n",
    "model_dir = r'E:\\Medical imaging\\Liver segmentation\\results' \n",
    "data_in = prepare(data_dir, cache=True)\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "model = UNet(\n",
    "    dimensions=3,#3-is 3D since we do volume segmentation\n",
    "    in_channels=1,#because we masked with only one channel(that means each slice has only one channel )\n",
    "    out_channels=2,#this value should be equal to the number of classes outputs (channel1- pixel prob. for background, channel2- pixel prob. for foreground)\n",
    "    channels=(16, 32, 64, 128, 256), \n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    "    norm=Norm.BATCH,\n",
    ").to(device)\n",
    "\n",
    "\n",
    "#loss_function = DiceCELoss(to_onehot_y=True, sigmoid=True, squared_pred=True, ce_weight=calculate_weights(1792651250,2510860).to(device))\n",
    "loss_function = DiceLoss(to_onehot_y=True, sigmoid=True, squared_pred=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-5, weight_decay=1e-5, amsgrad=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train(model, data_in, loss_function, optimizer, 600, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf728d4-e67d-44d9-a115-19578af745b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
